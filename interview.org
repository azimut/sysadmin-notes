- channel system design https://www.youtube.com/@ByteByteGo/videos

- https://github.com/checkcheckzz/system-design-interview
- https://github.com/donnemartin/system-design-primer
- https://github.com/karanpratapsingh/system-design
- https://github.com/lei-hsia/grokking-system-design
- https://github.com/shashank88/system_design

- https://github.com/ashishps1/awesome-behavioral-interviews
- https://github.com/mxssl/sre-interview-prep-guide
- https://github.com/bregman-arie/devops-exercises
  https://github.com/bregman-arie/devops-resources
  https://github.com/Tikam02/DevOps-Guide

- https://www.redhat.com/en/services/training/ex200-red-hat-certified-system-administrator-rhcsa-exam

* Course: InfraExpert
**  2 Welcome

- Interview Topics
  1) Networking
     - tcp/ip, udp, icmp, mac, ip, osi, load balancers
  2) OS:
     - processes
     - threads
     - concurrency
     - locks
     - mutex
     - semaphores
     - monitors
     - deadlocks
     - live locks
     - context switching
     - scheduling
  3) Unix/Linux
     - kernel, libraries, syscalls, memory managment, permissions, client server protocols
  4) NALSD (Non abstract design thinking)
     - design large scale system
     - give estimates (from a proposed solution)
     - answer vague design questions
     - provide specifics
     - mainly for SRE roles
  5) Troubleshooting
     - diagnose
     - roleplay with interviewer
  6) Coding
     - test code
     - corner cases
     - troubleshooting
     - large system applications
  7) Behavioural

**  3 What is a network?

- 1960-
- why? to share resources
  - printer, cds, exchange files, communication

- ~data link~ (me: the medium) through physical cables
- ~data exchange~ between devices

**  4 How the internet works?

- Client server model

**  5 Network Latency

- ~Latency~ is the difference between
  - when a packet was send and
  - when a packet was received

- ~Round-Trip Time~ RTT (aka x2 latency)
  - the time it takes to get a response back

- ~Throughput~
  - /average/ ammount of data that i can pass through a network

- ~Bandwith~
  - /maximum/ ammount of data that it can pass through a network.

**  6 Caching

- Can happen at many points of the system

- Goals (either) by storing in a more convenient location
  1) minimize latency
  2) minimize work

- ~Cache Invalidation~
  - Introduced by /mutable content/
  - To avoid /stale cache/

- When to consider caching?
  - if you only are going to be doing a read or a write of data
  - if you don't care about staleness
  - if you can invalidate stale data
  - if using a distributed system

- Types of cache
  - =Spatial=: caches also elements "near" the requested item.
  - =Temporal=: you keep the data with a timestamp
  - =Distributed=: temporal+spatial

- Implementations
  - =Write Through Cache=:
    - slow
    - solves inconsistency problem
    - new data is written to both simultaneuosly
      - main storage
      - cache
  - =Write Back Cache=
    - fast/asynchronous
    - more complex (difficult to maintain consistency)
      - algorithms used: fifo, lifo, lru, lfu
    - writes directly to cache
    - cache will handle the write to the main storage

- ~CDN~ proxy and content caching

**  7 OSI & TCP/IP models

- 1969
  There were no standarization for local network protocols between different vendors
  Neither on protocols or cables.

- "Protocol Wars" - TCP/IP vs OSI

**  8 OSI    Model

- 1994-
- Open Systems Interconnection
- Conceptual Framework
- Mnemonic:
  "A Priest Saw Two Nuns Doing Pushups"
  "All People Should Try New Dog Parks"
- Seven(7) Abstraction Layers
  1) Physical: hubs, voltages, electronic pulses, cables
  2) Data link: node to node data transfer, MAC, ~frames~, LLC (logical link control)
  3) Network: rcv/snd, IP, ~packets~
  4) Transport: delivery, error checking, tcp
  5) Session: controls conversation, sql
  6) Presentation: translates data, jpg, ascii, encrypt/decrypt
  7) Application: end user and app layer, web browser, http, https, smtp, ftp, dns

**  9 TCP/IP Model

- Mnemonic: "Always Try New Dog Parks"

- IPv4: 4 billion unique addresses
- IPv6: 340 undecillion
  - larger packages
  - more straighforward header

- Layers
  |----------------+---------------+------------------|
  | Application    | http ftp smtp | data             |
  | Transport      | tcp udp       | segments         |
  | Internet       | ip icmp arp   | packets/datagram |
  | Data Link      | ethernet      | frames           |
  | Physical (New) | cables NICs   | bits             |
  |----------------+---------------+------------------|

- IPv4 to IPv6 migration strategies
  - dual stacking
  - tunneling
  - NAT (has performance overhead)

** 10 TCP & UDP

- TCP Fields
  - Sequence Number: counter to keep track of each byte sent
    - 32 bit value
    - 5 bit timestampts
    - 3 bit MSS (maximum segment size)
    - 24 bit cryptographic hash function
  - Checksum: checks corrupted segments (16bit)

- Communication
  - < SYN 1
  - > ACK 1+N (N=Size of data)

- Handshake for ending a connection
  - < FIN N'
  - > SYN/ACK N'+1
  - > FIN 1
  - < SYN 2

- =Syn Cookies=
  - _Previously_
    After a SYN is received, a "buffer" is kept to keep
    the connection status while waiting for
    a response to the SYN/ACK.
  - _What?_
    In response this was created to avoid Syn-Flood attacks.
  - _How?_
    We reply with a SYN/ACK and forget about the connection
    By also sending the ~sequence number~ generated used a special function.
    Forgets about the connection.
    When receives an ACK, it checks the ~sequence number~ validity and accept or rejects based on it.

** 11 Routing Final (PPP,IP)

- At the data link level hosts can communicate through
  - Ethernet
  - PPP

- CIDR (Classless Inter-Domain Routing)

- Routing matches the longer prefix matched

- ~MTU~ Maximum Transmission Unit
  - Largest packet size of data that a device on the network can accept.
  - =1500 by Ethernet

- MSS
  - is detemined by  MTU
  - 1500 - 40 (of headers)
    1460

- Each devide on the route decreases the ~TTL~ value

** 12 Troubleshooting Final

- Mac: List all hardware
  $ networksetup -listallhardwareports

** 13 Operating Systems

- Before OS's, you had to manually load different programs into a computer.

- An OS is an intermediary between the user and the hardware.
- An os can
  - run other programs
  - have ~device drivers~ communicate between each other
  - thanks to ~scheduling~ allow to run multiple programs at the same time

08:00

* Course: System Design Interview    | NeetCode

1. https://colin-scott.github.io/personal_website/research/interactive_latency.html
2. https://en.wikipedia.org/wiki/Token_bucket
   https://en.wikipedia.org/wiki/Consistent_hashing
3. https://en.wikipedia.org/wiki/Least_frequently_used
   https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU
4. https://cloud.google.com/learn/what-is-object-storage
5. https://en.wikipedia.org/wiki/Content_delivery_network#Content_networking_techniques
6. https://en.wikipedia.org/wiki/Webhook
   https://en.wikipedia.org/wiki/Server-sent_events
   https://gist.github.com/CMCDragonkai/6bfade6431e9ffb7fe88 (one way?)
7. https://discord.com/blog/how-discord-stores-billions-of-messages
   https://discord.com/blog/how-discord-stores-trillions-of-messages
8. https://vitess.io/docs/resources/presentations/

** 0 How to Approach

1) In an interview you are basically defying the scope/requirements of the interview challenge.
   - Functional: aka features/scope
   - Non-Functional:
     * scalability
       - throughput (eg: daily active users, requests per seconds)
       - storage capacity
     * performance
       - latency
       - availability (#nr non error `div` # nr requests)

2) back of the envelope calculations
   |------+----------------------+-----------------------------|
   | 1s   |                      | 1 second                    |
   | 1ms  | milli                | 1 second divided 1 thousand |
   | 1us  | micro                | 1 second divided 1 million  |
   | 1ns  | nano                 | 1 second divided 1 billion  |
   |------+----------------------+-----------------------------|
   | mega | million              |                             |
   | giga | billion              |                             |
   | tera | trillion (3+billion) |                             |
   | peta | 15 zeroes            |                             |
   |------+----------------------+-----------------------------|

3) High Level Design

** 1 Rate Limiter

- First step is to define the ~functional requirements~
  - Why is the rate limiting being applied?
    - security
    - cost
    - availability
    - ux

- Then what we are protecting
  - backend api
    - distributed? (eg: each microservice)

- =Availability=
  - Fail
    1) Open: if it fails the rest should still keep working
    2) Closed: if it fails the rest should stop working

- Algorithm
  1) fixed window, meaning using wallclock timeframes
     + we don't have to keep track of when the request was made (more storage, simpler)
     + redis implementation with sorted set + expire
  2) sliding window
  3) token bucket
  4) sliding window counter

- database schema of the rules (not the ones getting updated each request)
  - id : string
  - api : string
  - endpoint : string
  - timeunit : string
  - request : int (number of request allowed)

** 2 Designing TinyUrl

- Non-Functional requirements
  - What are we going to be doing more? Reads? Writes?

- 62 characters available [0-9a-zA-Z]
- 8 characters length
- 62^8

- 1000 bytes per url
  1 billion new urls per month
  1 terabyte per month

- NoSQL
  - designed for large scale
  - we don't need an ACID properties or atomic transactions

- keep an in memory ~cache~ of "hot" urls mappings
  - algorithms
    1) LFU: least frequently used
    2) LRU: least recently used

- http redirections
  - 301 permanently moved, will be cached by the browser
  - 302 temporally moved

- one way to avoid tinurls hash collisions
  - we could pre-generate all/some the keys that are unused and provide them
  - the ACID, especially Atomicity and Isolation, would help avoid concurrency collisions
  - so some type of "row locking" on other database

** 3 Designing Twitter

- Requirements
  - a very read-heavy system
  - tweet
    - content (text/image/video)
    - interactions (like,retweet)
  - mvp
    - follow others
    - create tweets
    - view feed

- Calculations
  - 50M tweets created per day
  - 200M active users
    100 tweets a user sees per day
    20B tweet reads per day
  - 1MB avg space per tweet
    20PB data read per day

- Database
  - we have a relationship model when it comes to following feature
    we can implement sharding with both SQL/NoSQL
    table of tweets
    table of follows
  - sharding based on UID to help scale writes
  - media
    - separate (object) storage (GCS/S3)
    - or a distributed through a CDN in the middle of the object storage and the application
      - pull based CDN

- LRU cache of recent tweets or

- pub/sub
  - will receive new tweets and maintain a separate "feed cache"
  - skipping the database

** 4 Designing Discord

- What? Functional
  - groupchat application (eg: slack, teams)
    - sendMsg(body,server,channel)
    - polling for receiving? inneficient (lot of traffic/requests)
    - websockets for receiving or "http streaming"
  - we can resume where we left
    - viewChannel(pagination?,lastMsgReadTimestamp)
  - different channels on a group
  - notifications per channel/server

- Non Functional
  - low latency

- Calculations
  - 5M daily active users
  - 50M messages per day
  - 20k persons per server
  - 10k messages per day per server
  - 2k per message

- database (SQL)
  - medium scale
  - channelId for sharding (or serverId)
  - index by date (send_at)
  - tables:
    - messages: id, uid, mentionId, serverId, channelId, sent_at
    - userActivity: id, uid, serverId, channelId, last_read_at
      - for each user, for each channel they visited

- cache (in memory)
  - to keep the notifications/mentions counts
  - every time a message is sent, if it has a mention, it also goes to a KV store

- database (NoSQL) alternative
  - mongodb
    - original discord implementation
    - until the index (channelId,sent_at) didn't fit into memory
  - cassandra
    - partition index by channelId
    - cluster index by channelId+messageId

** 5 Designing Youtube

- Functional, What?
  - upload
  - watch

- Non-Functional
  - reliability (not corrupt/delete videos)
  - scale (thousands of viewers)
  - availability > consistency
  - Calculations
    - 1 B daily active users
    - 5 videos per day
    - 100 users watch per 1 uploading a video
    - 5B watched per day
      50M upload a day

- Object Storage
  - for raw uploaded files
  - for final encoded videos
  - upload(title,desc,video,userId)
  - =message queue= for encoding
  - CDN for video in Object Store

- NoSQL
  - to store metadata of the video and user info
  - large data
  - frequent reads
  - in memory cache for metadata access in NoSQL
  - mongodb
    - collections: video, user
    - we store duplicate references of information (to avoid relationships/joins)
    - on the rare batch updates, it could be done asynchronous

- Youtube uses MySQL's Vites

** 6 Designing Google Drive

- What? Cloud solution for files
  - (upload/download/remove)/edit/share/folders

- Non-Functional
  - 200M users
  - 50M daily active users
  - 15G available for free
  - 3000Pb of data (3 ExaBytes)
  - 2 file uploads per day

* Course: System Design Fundamentals | AlgoExpert
** Introduction
- More on the *knowledge* side than coding interviews that require *problem solving* skills
** What are Design Fundamentals?
- SDI Interviews
  - Questions are intentionally vague
    - You should take a prompt like "design uber" and turn it into a 45 minutes discussion
    - Questions: type system, functionality support, characteristics
  - Answers are more subjective
    - You need to justify why your solution took the decisions that it did
- SDF Categories
  | Knowledge       | client-server model, network protocols                     |
  | Characteristics | availability, latency, throughput, redundancy, consistency |
  | Components      | load balancers, caches, leader election, rate limiter      |
  | Tech            | Nginx, Zookeeper, Etcd, Redis, S3, Google Cloud Storage    |
** Client-Server Model/Architecture
- Client speaks to a Server
  Server listens for clients and then speaks back
** Network Protocols
- ip/tcp/http
- protocol is an agreed set of rules to interact between each other
- IP packet
  - header/data
  - limited in size, up to 2^16 bytes = 65000 Bytes = 0.065 MB
  - NO arrival or order guarantees
- TCP
  - ordered and arrival guarantess
  - error free way (uncorrupted)
- HTTP
  - Higher level abstraction: Easier to use than TCP/IP
  - Request-Response paradigm
  - You can have different methods (GET/POST/PUT/DELETE) band /paths and will respond accordingly
#+begin_src javascript
  const express = require('express');
  const app = express();
  app.use(express.json());
  app.listen(3000, () => console.log('Listening on port 3000.'));
  app.get('/hello', (req, res) => {
      console.log('req.headers: ', req.headers);
      console.log('req.method: ', req.method);
      res.send('Received GET request!\n');
  });
  app.post('/hello', (req, res) => {
      console.log('req.headers: ', req.headers);
      console.log('req.method: ', req.method);
      console.log('req.body: ', req.body);
      res.send('Received POST request\n');
  });
#+end_src
- on *curl* when you specify *--data* request method defaults to POST
** Storage
- most system requires some kind of storage
- A database is just a server.
  - Have different persistence depending if they persist on disk or on memory
- "Google Cloud Platform offers 8 different storage products"
*** Example: simple key-value storage both in memory and in disk
- JSON object send has to have a "data" field
> curl localhost:3001/memory/foo \
  --header 'Content-Type: application/json' \
  --data '{"data": "this is some data in memory."}'
> curl localhost:3001/memory/foo \
  -w "\n" ## adds a new line at the and of the response
#+begin_src javascript
  const express = require('express');
  const fs = require('fs');
  const DATA_DIR = 'aedb_data';
  const app = express();
  app.use(express.json());
  const hashtable = {};
  // ------------------------------
  app.post('/memory/:key', (req, res) => {
      hashtable[req.param.key] = req.body.data;
      res.send();
  });
  app.get('/memory/:key', (req, res) => {
      const key = req.params.key;
      if (key in hashtable) {
          res.send(hashtable[key]);
          return;
      }
      res.send('null');
  });
  // ------------------------------
  app.post('/disk/:key', (req, res) => {
    const destinationFile = `${DATA_DIR}/${req.params.key}`;
      fs.writeFileSync(destinationFile, req.body.data);
      res.send();
  });
  app.get('/disk/:key', (req, res) => {
      const destinationFile = `${DATA_DIR}/${req.params.key}`;
      try {
          const data = fs.readFileSYnc(destinationFile);
          res.send(data);
      } catch (err) {
          res.send('null');
      }
  });

  app.listen(3001, () => {
      console.log('Listening on port 3001');
  });
#+end_src
** Latency and Throughput
- They are not necesarilly correlated things
- there are 1M(10^6) "us" in one second
- Latency is how long it takes to data to traverse the system. From one point to another.
  - Operation: roundtrip of 1 packet (~1K) from California -> Netherlands = 150000 us
  - Operations: reading 1 Megabyte sequentially
   | memory        |   250 | us |
   | SSD           |  1000 | us |
   | 1Gbps Network | 10000 | us |
   | HDD           | 20000 | us |
- Throughput is how much work a machine can perform in a given period of time.
** Availability
- There is some implied level of guarentee in web services
- Ways to measure availability.
  - SLA/SLO: explicit availability
   | Service Level Agreement | explicit agreement between Service Provider and Customers |
   | Service Level Objective | the components of SLA, eg: %uptime, nr of errors          |
    - Cloud Spanner SLA - monthly uptime percentage
      - >= 99.999% - Multi-regional instance
      - >= 99.99%  - Reginal instance
      - If they don't comply, they paid back
    - Some services might require more HA than others
      - You need to think when you design them
  - Nines:
    - Percentage of system uptime on a given year. And all primary functions are satisfied
    - "five nines" is considered the "gold standard" of availability
    - Measured with on the ammount of "9", downtime per year
      | availability | nines | downtime | unit    |
      |--------------+-------+----------+---------|
      |          90% | one   |       36 | days    |
      |          99% | two   |     3.65 | days    |
      |        99.9% | three |     8.77 | hours   |
      |       99.99% | four  |    52.60 | minutes |
      |      99.999% | five  |     5.26 | minutes |
      |     99.9999% | six   |    31.56 | seconds |
- Redundancy
  - Multiplying parts of your system
    - Adding servers
    - Adding LBs
  - No have a SPF (single point of failure)
  - Types
    - Passive redundancy: using the excess of capacity(servers) in the case of component failures
    - Active redundancy: when the components *know* of the failure and start to take the work of the broken component (eg: leader election)
** Caching
- In algorithms we use caching to improve the time complexity of them.
  To avoid redoing the same operations, especially the _computationally_ complex.
- ~Caching~
  - is storing data in a location that is different and faster from where the original data is from.
  - Used to redeuce or improve the =latency= of a system
- Where
  - computationaly complex ops
  - in hardware (L1/L2/L3)
  - network
    - on client: cache server requests
    - on server: cache database results
    - in between (client/server/database)
- Types of caches (ME: that deal with invalidation)
  - ~Writetrough cache~
    on the same write operation BOTH server cache and database will be writethough
  - ~Writeback cache~
    write operation ONLY updates the server cache, database is updated at a later time asynchronously
- Staleness, caches can become stale if they haven't been updated properly.
  - For some content it might be acceptable to have stale cache
- When to use caching?
  - if you have a single thing reading/writing
  - if you don't care about consistency or staleness of data
  - if the *data* you are dealing with is static/immutable
  - if you are dealing with *data* that is mutable
    - you are going to add new places where the data would exists
    - check for data being on sync
- ~Eviction policy~
  - Types
    - LRU: Less Recently Used
    - LFU: Less Frequency Used
    - FIFO
    - Random
  - Why?
    - Because we don't have infinite storage
    - To get ride of stale data
*** Example: nodejs express cache on a dictionary
#+NAME: server.js
#+begin_src js
  const database = require('./database');
  const express = require('express');
  const app = express();
  const cache = {};

  app.get('/nocache/index.html', (req, res) =>{
    database.get('index.html', page => {
      res.send(page);
    });
  });

  app.get('/withcache/index.html' , (req, res) => {
    if ('index.html' in cache) {
      res.send(cache['index.html']);
      return;
    }
    database.get('index.html', page => {
      cache['index.html'] = page;
      res.send(page);
    });
  });

  app.listen(3001, () => {
    console.log('Listening on port 3001');
  });
#+end_src
#+NAME: database.js
#+begin_src js
  const database = {
    ['index.html']: '<html>HelloWorld!</html>',
  };

  module.exports.get = (key, callback) => {
    setTimeout(() => {
      callback(database[key]);
    }, 3000);
  };
#+end_src
** Proxies
- Types
  1) Reverse Proxy:
     - Act on behalf of the server
     - The client won't know that the request is going to the reverse proxy.
     - Features:
       - Can filter out some requests
       - Can do logging
       - Can cache certain things
       - Can act as a load balancer
  2) Forward Proxy: most commonly refered to as "proxy"
     - Acts in behalf of the clients
     - Can hide the identity of the client that is connecting to the server
*** Example: nginx + nodejs
#+NAME: server.js
#+begin_src js
  const express = require('express');
  const app = express();
  app.listen(300, () => console.log('listening on port 3000.'));
  app.get('/hello', (req, res) => {
    console.log(req.headers);
    res.send('Hello\n');
  });
#+end_src
#+NAME: nginx.conf
#+begin_src conf
events { }
http {
  upstream nodejs-backend {
    server localhost:3000;
  }
  server {
    listen 8081;
    location / {
      proxy_set_header systemexpert-tutorial true;
      proxy_pass http://nodejs-backend;
    }
  }
}
#+end_src
** Load Balancers
- Clients -> LB -> Servers
- There are Software and Hardware LB's
- Has the job of balancing workloads across resources
- Helps to /horizontally scale/ our system
  - better throughput
  - better response time
*** Server Selection
 | Random                 |                                                        |
 | Round-Robin            | in sequential order                                    |
 | Weighter-Round-Robin   | it order, but it repeats more those with more "weight" |
 | Performance/Load based | by doing keeping and doing healthchecks on each server |
 | IP based               | by hashing the source IP                               |
 | Path based             | according to the HTTP path, isolates impact of changes |
- You can use multiple server selections techniques, eg: by using multiple LBs
*** Example
#+NAME: server.js
#+begin_src js
  const express = require('express');
  const app = express();
  const port = process.env.PORT;
  app.listen(port, () => console.log(`Listening on port ${port}.`));
  app.get('/hello', (req,res) => {
    console.log(req.headers);
    res.send(`Hello from port ${port}.\n`);
  })
#+end_src
- PORT=3000 node server.js
  PORT=3001 node server.js
#+NAME: nginx.conf, weighted round robin
#+begin_src conf
  events { }
  http {
     upstream nodejs-backend {
        server localhost:300 weight=3;
        server localhost:3001;
     }
     server {
        listen 8081;
        location / {
            proxy_set_header sytemexpert-tutorial true;
            proxy_pass http://nodejs-backend
        }
     }
  }
#+end_src
** Hashing
- Hashing is transforming some input into some fixed size output
- Regular LBs strategy can have some particular requests that are too expensive.
  Caching can fix this.
  But with round-robin we won't be able to use that cache.
*** =Simple Hashing=
  - mod()s the hash number
  - doesn't work well with architectures that add/remove servers often
*** =Consistent Hashing=
  - both servers and clients are hashed and put into a cycle/circle
  - clients, pick the next server clockwise in the circle
  - aka mantains consistency between hashes and buckets
  - additionally to ensure balance,
    you can hash the servers several times through different hash function and add them all
    while also you can aso add more locations of a single server
*** =Rendezvous Hashing=
- 1996, at the same time of C.H.
- h() obtains a *list of priorities* for each server, from the input, and it picks the higher one
- h(Sn, O) = Wn
  | h() | hash function                         |
  | Sn  | the servers                           |
  | O   | origin server, the thing being hashed |
  | Wn  | a weight or priority                  |
- https://en.wikipedia.org/wiki/Rendezvous_hashing
- https://www.youtube.com/watch?v=1TIzPL4878Q
- You calculate scores for your servers/destinations pick the highest one.
**** Example
- We keep consistency. But none of the servers picked are equal.
#+NAME: hashing_utils.js
#+begin_src js
  const utils = require('./hashing_utils');
  const serverSet1 = [ 'server0', 'server1', 'server2' ];
  const serverSet2 = [ 'server0', 'server1', ];
  const usernames = ['username0', 'username1', 'username2'];

  function pickServerSimple(username, servers) {
    const hash = utils.hashString(username);
    return servers[hash % servers.length];
  }

  function pickServerRendezvous(username, servers) {
    let maxServer = null;
    let maxScore = null;
    for(const server of servers) {
      const score = utils.computeScore(username, server);
      if (maxScore == null || score > maxScore) {
        maxScore = score;
        maxServer = server;
      }
    }
    return maxServer;
  }
  console.log('Simple Hashing Strategy:');
  for(let username of usernames) {
    const server1 = pickServerSimple(username, serverSet1);
    const server2 = pickServerSimple(username, serverSet2);
    const serversAreEqual = server1 === server2;
    console.log(`${username}: ${server} => ${server2} | equal: ${serversAreEqual}`)
  }

  console.log('\nRendezvous Hashing Strategy:');
  for(let username of usernames) {
    const server1 = pickServerRendezvous(username, serverSet1);
    const server2 = pickServerRendezvous(username, serverSet2);
    const serversAreEqual = server1 === server2;
    console.log(`${username}: ${server} => ${server2} | equal: ${serversAreEqual}`)
  }

#+end_src
#+NAME: hashing_example.js
#+begin_src js
  function hashString(string) {
    let hash = 0;
    if (string.length === 0) return hash;
    for (let i = 0; i < string.length; i++) {
      charcode = string.charCodeAt(i);
      hash = (hash << 5) - hash + charCode;
      hash |= 0;
    }
    return hash;
  }
  function computeScore(username, server) {
    const usernameHash = hashString(username);
    const serverhash = hashString(server);
    return (usernameHash * 13 + serverHash * 11) % 67;
  }
  module.exports.hashString = hashString;
  module.exports.computeScore = computeScore;
#+end_src
** Relation Databases
- Google Cloud DataStore: NoSQL database
  - It provides his own query language (GQL) that might not be able perform some simple queries
- Tables = Relations
- Row    = Records
- Tables are structures imposed that store data. Typically represent a specific entity.
- Must provide ACID (Atomicity Consistency Isolation Durability)
  - A: means that the whole *transaction* is a unit, if something fails on it all fails
  - C: must take into account past *transactions* done on the database, no stale state
  - I: multiple *transaction* can occur at the same time, in reality they run sequentially
  - D: effects on the *transaction* are permanent
- The key benefit of an ~index~ is that you can lookup records/rows from O(n)
  to O(1) or O(log n) depending of the type of index.
- 00:30
  a transaction atomicity can be seen on the CLI, within the transaction you would see the changes
  but outside (aka on another CLI) you will NOT see the changes.
- a transactions might lock another one, to ensure isolation
*** Example create.sql
#+begin_src sql
  create table payments (
    customer_name varchar(128),
    processed_at date,
    amount int
  );
  create table balances (
    username varchar(128),
    balance int
  );
  create table large_able (
    random_int int
  );
  insert into payments values ('clement', '2019-12-15', 10);
  insert into payments values ('antoine', '2020-01-01', 100);
  insert into payments values ('clement', '2020-01-02', 10);
  insert into payments values ('antoine', '2020-01-02', 100);
  insert into payments values ('antoine', '2020-01-03', 100);

  insert into balances values ('antoine', 0);
  insert into balances values ('clement', 1000);

  insert into large_table (random_int)
  select round(random()*1000000000)
    from generate_series(1,50000000) s(i);
#+end_src
*** Example queries.sql
#+begin_src sql
  -- sum the number of payments for each user
  select customer_name, count(*)
    from paymets
   group by customer_name
   order by count desc;
  -- sum the payment amounts for each month
  select sum(amount), extract(year from processed_at) as year, extract(month from procssed_at) as month
    from payments
   group by month, year
   order by sum desc;
  -- sum the payments amounts for each month for each user
  select customer_name, sum(amount), extract(year from processed_at) as year, extract(month from procssed_at) as month
    from payments
   group by customer_name, month, year
   order by sum desc;
  -- find the largest single-user payments for each month
  select max(amount), year, month
    from (
      select customer_name, sum(amount) as amount, extract(year from processed_at) as year, extract(month from processed_at) as month
        from payments
       group by customer_name, month, year
      ) as montly_sums
   group by year, month;
#+end_src
*** Example transactions.sql
#+begin_src sql
  begin transaction;
  update balances set abalance = balance - 100 where username = 'clement';
  update balances set balance = balance + 100 where username = 'antoine';
  commit;
#+end_src
** Key-Value Stores
- One of the most popular NoSQL databases
- Good for caching or dynamic configuration (eg: etcd)
*** Example: redis backed key/value cache with key being the page
#+NAME: server.js
#+begin_src js
  const database = require('./database');
  const express = require('express');
  const redis = require('redis').createClient();
  const app = express();
  app.get('/nocache/index.html', (req,res) => {
    database.get('index.html', page => {
      res.send(page);
    });
  });
  app.get('/withcache/index.html', (req,res) => {
    redis.get('index.html', (err, redisRes) => {
      if (redisRes) {
        res.send(redisRes);
        return;
      }
      database.get('index.html', page => {
        redis.set('index.html', page, 'EX', 10); // set with expiration of 10 seconds
        res.send(page);
      });
    })
  });
  app.listen(3001, function() {
    console.log('Listening on port 3001');
  });
#+end_src
#+NAME: database.js
#+begin_src js
  const database = {
    ['index.html']: '<html>Hello world!</html>',
  };
  module.exports.get = (key, vallback) => {
    setTimeout(() => {
      callback(database[key]);
    }, 3000)
  };
#+end_src
** Specialized Storage Paradigms
| =Type=         | =Implementation=     | =Description=                           | =Example=              |
|----------------+----------------------+-----------------------------------------+------------------------|
| Blob Store     | GCS, S3              | large amount of unstructured data       | image file, executable |
|                |                      | behave /like/ k/v storage               |                        |
|----------------+----------------------+-----------------------------------------+------------------------|
| Time Series DB | InfluxDB, Prometheus | for ts type computations (eg: roll avg) | monitoring, prices     |
|----------------+----------------------+-----------------------------------------+------------------------|
| Graph DB       | Neo4J                | relationships is core to them           | social network         |
|                |                      | when there are a lot of relationships   |                        |
|----------------+----------------------+-----------------------------------------+------------------------|
| Spatial DB     |                      | anything that has geometric space       | locations in a map     |
| + Quadtree     |                      | QT is a type of "spatial index"         |                        |
|----------------+----------------------+-----------------------------------------+------------------------|
- BLOB: Binary Large OBject
- Quadtree
  - O(log 4 n) for lookup
  - You can think of it as a grid
    - For spatial dbs, you keep subdividing if there are locations on the cuadrant
  - Each node on it has 4 or none child node
*** Example: Neo4J vs SQL
- Problem:
  Out of all interviewrs that interviewed clement that failed him, which had intervied in facebook and failed
**** cypher.cql - insert data nodes and relationships
#+begin_src sql
  create (facebook:Company {name:'Faceook'})

  create (clement:Cadidate {name:'Clement'})
  create (antoine:Cadidate {name:'Antoine'})
  create (simon:Cadidate   {name:'Simon'})

  create (alex:Interviewer    {name:'Alex'})
  create (meghan:Interviewer  {name:'Meghan'})
  create (marli:Interviewer   {name:'Marli'})
  create (sandeep:Interviewer {name:'Sandeep'})
  create (molly:Interviewer   {name:'Molly'})

  create (alex)-[:INTERVIEWED {score: 'passed'}]->(clement)
  create (marli)-[:INTERVIEWED {score: 'failed'}]->(antoine)

  create (ryan)-[:APPLIED {status: 'rejected'}]->(facebook)
  create (simran)-[:APPLEID {status: 'accepted'}]->(facebook)
  #+end_src
**** cypher.cql - query
#+begin_src sql
  match (interviewer:Interviewer)-[:INTERVIEWED {score:'failed'}]->{:Candidate {name:'Clement'}}
  where (interviewer)-[:APPLIED {status:'rejected'}]->{:Company {name:'Facebook'}}
  return interviewer.name;
#+end_src
**** sql_query.sql
complex to understand and slow to run
#+begin_src sql
  select interviewers.name
    from (
      candidates
      join interviews on (candidates.id = interviews.candidate_id and candidates.name = 'Clement' and interviews.score = 'failed')
      join interivewers on (interviewers.id = interviewers.interviewer_id)
    )
   where exists (
     select *
       from applications
      where company = 'Facebook' AND candidate_id = interviewers.id and status = 'rejected'
   );
#+end_src
** Replication and Sharding
- Some systems performance and availability can be limited due their database
- Replication: replica takes over
  - Writes needs to be *sync* for failovers, it costs some time
    Writes can be *async* for better latency
  - Main database -a/sync--> Replica
- Sharding
  - Is splitting/partition the data into "shards"
  - When you have a lot of data, and replication is not optimal.
  - Where is the logic that picks the shards?
    1) in the application code
    2) on a reverse proxy
  - Types
    1) Rows:
       - for example, firstnames starting a-c, d-h,... each in separate shards
       - They might create *hotspots* aka shards with more data
    2) Hashing:
       - ensures uniformity
       - but isn't good with availability by itself without replicas
- PORT=3000 DATA_DIR=aedb_data_0 node aedb.js
  PORT=3001 DATA_DIR=aedb_data_1 node aedb.js
  node aedb_projxy.js
  curl --header 'Content-type: application/json' --data '{"data": "This is some data."}' localhost:8000/a
  curl -w "\n" ocalhost:8000/a
*** Example: aedb.js - storing data on disk
#+begin_src js
  const express = require('rexpress');
  const fs = require('fs');
  const PORT = process.env.PORT;
  const DATA_DIR = process.env.DATA_DIR;
  const app = express();
  app.use(express.json());
  app.post('/:key', (req, res) => {
    const {key} = req.params;
    console.log(`Storing data at key ${key}.`);
    const destinationFile = `${DATA_DIR}/${key}`;
    fs.writeFileSync(destinationfile, req.body.data);
    res.send();
  });
  app.get('/:key', (req,res) => {
    const {key} = req.params;
    console.log(`Retrieving data from ${key}`);
    const destinationFile = `${DATA_DIR}/${key}`;
    try {
      const data = fs.readFileSync(destinationFile);
    } catch (err) {
      res.send('null');
    }
  });
  app.listen(PORT, () => {
    console.log(`listening on port ${PORT}!`);
  })
#+end_src
*** Example: aedb_proxy.js - reverse proxy
#+begin_src js
  const axios = require('axios');
  const express = require('express');
  const SHARD_ADDRESSES = ['http://localhost:3000', 'http://localhost:3001'];
  const SHARD_COUNT = SHARD_ADDRESSES.length;
  const app = express();
  app.use(express.json());
  function getShardEndpoint(key) {
    const shardNumber = key.charCodeAt(0) % SHARD_COUNT;
    const shardAddress = SHARD_ADDRESSES[shardNumber];
    return `${shardAddress}/${key}`;
  }
  app.post('/:key', (req,res) => {
    const shardEndpoint = getShardEndpoint(req.params.key);
    console.log(`Fowarding to: ${shardEndpoint}`);
    axios
    .post(shardEndopint, req.body)
    .then(innerRes => {
      res.send();
    });
  });
  app.get('/:key', (req,res) => {
    const shardEndpoint = getShardEndpoint(req.params.key);
    console.log(`Forwarding to: ${shardendpoint}`);
    axios
      .get(shardEndpoint)
      .then(innerRes => {
        if (innerRes.data === null) {
          res.send('null');
          return;
        }
        res.send(innerRes.data);
    });
  });
  app.listen(8000, () => {
    console.log('listening port 8000');
  })
#+end_src
- 19:27
** Leader Election
- Example: program that allows users to subscribe a product on a regular basis
  - Components
    - Database
    - 3rd-Party Service: takes care of charging the users, debiting funds (eg: paypal/stripe)
    - Service that connects the /database/ to the /3rd party service/.
      Can be replicated for HA, with proper ~leader election~ to avoid duplicated tasks.
      Leader will be the one doing the request.
      Followers on standby.
- Roles: leader on the group of servers is picked through ~leader election~
  - leader
  - followers
- Challenge is mainly on gaining *consensus* and sharing some state.
- Consensus
  - Algorithms: Paxos, Raft
  - Software: etcd, zookeeper
- With the *consensus* problem solved by *etcd*, you can then have a key/value like "leader=host1" which give you leader election
*** Example
- python leader_election.py server1
  python leader_election.py server2
  python leader_election.py server3
  python leader_election.py server4
#+NAME: leader_election.py
#+begin_src python
  import etcd3
  import sys
  import time
  from threading import Event

  LEADER_KEY = "/algoexpert/leader"

  def main(server_name):
      client = etcd3.client(host="localhost", port=2379)
      while True:
          is_leader, lease = leader_election(client, server_name)
          if is_leader:
              print("I am the leader.")
              on_leadership_gained(lease)
          else:
              print("I am a follower.")
              wait_for_next_election(client)

  # This election mechanism consists of all clients trying to put their name
  # into a single key, but ina way that only works if the key does not
  # exists (or has expired before).
  def leader_election(client, server_name):
      print("New leader election happening.")
      # Create a lease before creating a key. This way, if this client ever
      # lets the lease expire, the keys associated with that lease will all
      # expire as well.
      # Here, if te client fails to renew lease for 5 seconds (network
      # partition or machine goes down), then the leader election key will
      # expire.
      lease = client.lease(5) # 5 seconds lease

      # Try to create the key with your name as the value. If it fails, then
      # another server got there first.
      is_leader = try_insert(client, LEADER_KEY, server_name, lease)
      return is_leader, lease

  def on_leadership_gained(lease):
      while True:
          # As long as this process is alive and we're the leader,
          # we try to renew the lease. We don't give up leadership
          # unless the process / machine crashes or some exception
          # is raised.
          try:
              print("Refreshing lease; still the leader.")
              lease.refresh()
              do_work() # business logic goes here
          except Exception:
              # Here we most likely got a client timeout (from
              # network issue). Try to revoke the current lease
              # so another member can bget leadership.
              lease.revoke()
              return
          except KeyboardInterrupt:
              print("\nRevoking lease; no longer the leader.")
              lease.revoke()
              sys.exit(1)

  def wait_for_next_election(client):
      election_event = Event()
      def watch_callback(resp):
          for event in resp.events:
              # It means the key expired / got deleted, which means the
              # leadership is up for grabs.
              if isinstance(event, etcd3.events.DeleteEvent):
                  print("LEADERSHIP CHANGE REQUIRED")
                  election_event.set()
      watch_id = client.add_watch_callback(LEADER_KEY, watch_callback)
      # While we haven't seen that leadership needs change, just sleep.
      try:
          while not election_event.is_set():
              time.sleep(1)
      except KeyboardInterrupt:
          client.cancel_watch(watch_id)
          sys.exit(1)

      # Cancel the watch; we see that election should happen again.
      client.cancel_watch(watch_id)

  # Try to insert a key into etcd witha  value and a lease. If the lease expires
  # that key willg et automatically deleted behind the scnes. I fthat key
  # wa already present, this will raise an exception.
  def try_insert(client, key, value, lease):
      insert_succeded, _ = client.transaction(
          failure=[],
          success=[client.transactions.put(key, value, lease)],
          compare=[client.transactions.version(key) == 0],
      )
      return insert_succeded

  def do_work():
      time.sleep(1)

  if __name__ == "__main__":
      server_name = sys.argv[1]
      main(server_name)
#+end_src
** Peer-to-Peer Networks
- Example: a system to deploy large files to thousands of machines at once. From one of them to all the other.
- Solutions
  1) on a regular network. Have all machines download it from 1 machine.
  2) *get the file to N machines*, and have them serve the file. Requests will split among them.
  3) *sharding the files*. Still has all machines fetching a shard from 1 machine.
  4) *peer-to-peer network*
     Split the file in chunks and sent it to all the peers.
     Let the rest build the whole file.
     With this, peers will not have a need to wait and they could actively send chunks themselves.
     They would need to know which peer to talk next (*peer discovery*)
- Machine = Peers
- Peer Discovery: How?
  - with a tracker, a central database of peers
  - gossip/epidemic protocol, by using a distributed hash table (aka DHT)
- Real World Use case
  - https://github.com/uber/kraken P2P Docker registry capable of distributing TBs of data in seconds
  - Torrent
** TODO Pooling and Streaming
- For when you need to have access to a constantly changing piece of information. eg: temperature
- *Polling*: as you reduce the polling frequency you increase the load on the servers
  Clients -every X seconds-> Servers
          <-----------------
- *Streaming*: typically a socket
  Clients <--continuous push-- Servers
*** Example: messaging_api.js
#+begin_src js
  const axios = require('axios');
  const WebSocket = require('ws');
  function createMessagingSocket() {
    return new WebSocket('ws://localhost:3001/messages');
  }
  function getMessages() {
    return axios.get('http://localhost:3001/messages')
      .then(res => res.data);
  }
  function sendMessage(message) {
    return axios.post('http://localhost:3001/messages', message);
  }
  module.exports.createMessagingSocket = createMessagingSocket;
  module.exports.getMessages = getMessages;
  module.exports.sendMessage = sendMessage;
#+end_src
*** Example: helpers.js
#+begin_src js
  function getRandomInt(max) {
    return Math.floor(Math.random() * Math.floor(max));
  }
  module.exports.getRandomInt = getRandomInt;
#+end_src
*** Example: server.js
#+begin_src js
  const express = require('express');
  const expressWs = require('express-ws');
  const app = express();
  expressWs(app);
  const messages = [{id: 0, text: 'Welcome!', username: 'Chat Room'}];
  const sockets = [];
  app.use(express.json());
  app.listen(3001, () => {
    console.log('Listening on port 3001!');
  });
  app.get('/messages', (req, res) => {
    res.json(messages);
  });
  app.post('/messages', (req, res) => {
    const message = req.body;
    messages.push(message);
    for (const socket of sockets) {
      socket.send(JSON.stringify(message));
    }
  });
  app.ws('/messages', socket => {
    socksets.push(socket);
    socket.on('close', () => {
      sockets.splice(sockets.indexOf(socket), 1);
    });
  });
#+end_src
*** Example: client.js
#+begin_src js
  const helpers = require('./helpers');
  const messagingApi = require('./messaging_api');
  const readline = require('readline');
  const displayedMessages = {};
  const terminal = readline.createInterface({
    input: process.stdin,
  });

  terminal.on('line', text => {
    const username = process.env.NAME;
    const id = helpers.getRandomInt(100000);
    displayedMessages[id] = true;
    const message = {id, text, username};
    messagingApi.sendMessage(message);
  });

  function displayMessage(message) {
    console.log(`> ${message.username}: ${message.text}`);
    displayedMessages[message.id] = true;
  }

  async function getAndDisplayMessages() {
    const messages = await messagingApi.getMessages();
    for (const message of messages) {
      const messageAlreadyDisplayed = message.id in displaedMessages;
      if (!messageAlreadyDisplayed) displayMessage(message);
    }
  }
#+end_src
** Configuration
- Most large scale distributed systems, are going to be relying on configuration
- A set of parameters, constants that your application are going to use
  Not on your code.
  On an isolated file.
- Types:
  1) Static:
     Packaged/shipped with your application code
     You have to wait until the code is deployed.
  2) Dynamic:
     Backed by some database.
     Immediate changes.
     Needs tooling to make them safer. (eg: access control, approval, controlled deploy)
*** Example: config.json
#+begin_src json
  {
    "apiKey": "asdbasdas_1231",
    "showSystemsExpert": false,
    "supportedLanguages": [
      "cpp",
      "csharp",
      "go"
    ],
    "version": {
      "number": 0,
      "releaseDate": "2020-02-20"
    }
  }
#+end_src
*** Example: config.yaml
#+begin_src yaml
  apiKey: asodijaos_123123
  shoSystemsExpert: false
  supportedLangueges:
    - cpp
    - csharp
    - go
  version:
    number: 0
    releaseDate:
#+end_src
*** Example: server.js
#+begin_src javascript
  const fs = require('fs');
  const express = require('express');
  const app = express();
  const staticConfig = JSON.parse(fs.readFileSync('static_config.json'));
  app.listen(3000, () => console.log('Listening on port 3000.'));
  app.get('/static/new_feature.html', function(req, res) {
    if (!staticConfig.newFeatureLaunched) {
      res.status(401).send('unauthorized.\n');
      return;
    }
    res.send('<html>Hello World!</html>\n');
  });
#+end_src
** 20 Rate Limiting
- Is setting thresholds to some operations, after which they will return errors.
  Limiting the amount of *operations* that can be performed in a given amount of *time*.
- protects you from DoS attacks
- eg: per user, per ip address, on region, on the whole system (eg: max 10k requests)
*** Example
**** database.js
#+begin_src javascript
  const database = {
    ['index.html'] = '<html>hello world!</html>',
  };
  module.exports.get = (key, callback) => {
    setTimeout(() => {
      callback(database[key]);
    }, 1000);
  };
#+end_src
**** server.js
#+begin_src javascript
  const database = require('./database');
  const express = require('express');
  const app = express();

  // keep a hash table of he previous access time for each user.
  const accesses = {}

  app.listen(3000, () => console.log('Listening on port 3000.'));
  app.get('/index.html', function(req, res) {
    const {user} = req.headers; // assumes there is an user, irl could be auth creds...
    if (user in accesses) {
      const previousAccessTime = accesses[user];
      // limit to 1 request every 5 seconds
      if (Date.now() - previousAccessTime < 5000) {
        res.status(429).send('too many requests.\n');
        return;
      }
    }
    // serve the page and store this access time
    database.get('index.html', page => {
      accesses[user] = Date.now();
      res.send(page + '\n');
    });
  }
#+end_src
** 21 Logging and Monitoring
** 22 Publish and Subscribe Patterns
** 23 MapReduce
** 24 Security and HTTPS
** 25 API Design
