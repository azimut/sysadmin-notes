#+TITLE: ffmpeg

- 2000
- Fast Forward ffmpeg

- tool https://www.scenedetect.com/
- tool (dead) https://zackoverflow.dev/writing/ffmpeg-guide
- tool https://evanhahn.github.io/ffmpeg-buddy/
- tool: web UI
  source https://github.com/antiboredom/ffmpeg-explorer
  ui https://lav.io/notes/ffmpeg-explorer/
  live https://ffmpeg.lav.io/
  filters map https://raw.githubusercontent.com/antiboredom/ffmpeg-explorer/main/filternames.txt
  discussion https://news.ycombinator.com/item?id=37269425

- library (filter_complex support) https://github.com/kkroening/ffmpeg-python
- tool/snippets https://amiaopensource.github.io/ffmprovisr/
- tool https://ffmpegbyexample.com/
- tool https://github.com/smacke/ffsubsync
- tool https://github.com/fujiawei-dev/ffmpeg-generator
- tool https://github.com/richardpl/lavfi-preview
- tool models for arnndn https://github.com/GregorR/rnnoise-models

- tutorial https://github.com/leandromoreira/ffmpeg-libav-tutorial
- guide https://trac.ffmpeg.org/wiki/Encode/H.264
- examples https://hhsprings.bitbucket.io/docs/programming/examples/ffmpeg/index.html

* cli

|------------------+------------------------------------|
|       <c>        |                                    |
| -filter:v fps=30 | 60 to 30 fps                       |
|      -ac 1       | mono                               |
|       -vn        | remove video                       |
|      -r FPS      |                                    |
|      -crf N      | Constant Rate Factor (aka quality) |
|    -pixfmt P     |                                    |
| -vcodec ? -c:v ? | specify video codec                |
| -acodec ? -c:a ? | specify audio codec                |
|------------------+------------------------------------|

* codecs

- copy
- libx264

* language

- falsy: 0
- truthy: non-zero
- color range: 0-255

** expressions

- manual https://www.ffmpeg.org/ffmpeg-all.html#Expression-Evaluation
- source https://ffmpeg.org/doxygen/2.4/eval_8c_source.html

operators
binary: + - * / ^
 unary: + -

bitand(x, y)
 bitor(x, y) x and y are converted to integers before executing the bitwise operation.

print(exp)
print(exp, level)

time(0) Return the current (wallclock) time in seconds.

*** local internal variables

root(expr, max)
    Find an input value for which the function represented by expr with argument ld(0) is 0 in the interval 0..max.

    The expression in expr must denote a continuous function or the result is undefined.

    ld(0) is used to represent the function input value, which means that the given expression will be evaluated multiple times with various input values that the expression can access through ld(0). When the expression evaluates to 0 then the corresponding input value will be returned.

ld([0-9])       : global[idx]
st([0-9], expr) : global[idx] = expr
    Note: variables are currently =not shared between expressions.=

*** random

random([0-9])            returns between 0.0 and 1.0, takes a seed from a glob between [0-9]
randomi([0-9], min, max) returns between MIN and MAX, takes a seed from a glob between [0-9]

*** boolean - return 1 if...

not
isinf isnan
eq/2  between/3
gt/2  gte/2 lt/2  lte/2

*** control flow

if/2  if/3  ifnot/2  ifnot/3
while/2

*** math / numbers

PHI    PI      E
ceil   floor   round  trunc
cos    cosh    acos
sin    sinh    asin
tan    tanh    atan   atan2/2
abs    pow/2   exp    log
mod/2  min/2   max/2  sqrt
clip/3 hypot/2 lerp/3
gcd/2  sgn
gauss(x) Compute Gauss function of x, corresponding to exp(-x*x/2) / sqrt(2*PI).
squish(x) Compute expression 1/(1 + exp(4*x)).
taylor(expr, x)
taylor(expr, x, idx)

    Evaluate a Taylor series at x, given an expression representing the ld(idx)-th derivative of a function at 0.

    When the series does not converge the result is undefined.

    ld(idx) is used to represent the derivative order in expr, which means that the given expression will be evaluated multiple times with various input values that the expression can access through ld(idx). If idx is not specified then 0 is assumed.

    Note, when you have the derivatives at y instead of 0, taylor(expr, x-y) can be used.

** encoders            (-vcodec -codec:v)

#+begin_src sh
  $ ffmpeg -encoders
  Encoders:
   V..... = Video
   A..... = Audio
   S..... = Subtitle
   .F.... = Frame-level multithreading
   ..S... = Slice-level multithreading
   ...X.. = Codec is experimental
   ....B. = Supports draw_horiz_band
   .....D = Supports direct rendering method 1
#+end_src

- source filters: do NOT have inputs
- sink filters: do NOT generate outputs

** simple filters      (-vf/-af/-filter:v/-filter:a)

https://ffmpeg.org/ffmpeg-filters.html

#+begin_src sh
  $ ffmpeg -h filter=<FILTER> # show help for FILTER
  $ ffmpeg -filters
  Filters:
    T.. = Timeline support
    .S. = Slice threading (support)
    ..C = Command support (aka it can be used outside the video filter)
    A = Audio input/output
    V = Video input/output
    N = Dynamic number and/or type of input/output
    | = Source or sink filter
#+end_src

- have 1 input, and 1 output
- typeof(input) == type(output)
- you can daisy-chain multiple *simple filters*, to create a ~filter chain~
  - uses ~,~ between filters
- timeline support is given through the ~enable~ parameter which accepts ~between(t,N,M)~ joined by ~+~
- variables https://www.ffmpeg.org/ffmpeg-filters.html#Options-1
  - iw,ih - input width and input height
  - t - point of time of the video, in seconds
  - pts
- filtering doesn't allow stream copy

#+begin_src sh
  filter1=          # space optional
    opt1=arg1:
    opt2=arg2,
  filter2=
    opt1=arg1
  filter3=arg1:arg2 # shortform
#+end_src

** complex filtergraph (-lavfi/-filter_complex)

- filtergraph
- can have multiple (or none) inputs and multiple outputs
  - of different types
- between non-liner/complex filters use ~;~ as a delimiter
- can't use the same output stream label twice
  - use filters split/asplit if needed
- labels:
  - each ~-i~ is automatically mapped to "[N]" in the script
    - starting at 0
  - can sub-reference audio/video streams through [N:a] or [N:v] respectively
  - [in] and [out]
  - can have the same label name for input and output
- you can directly map OUTPUT many videos by
  #+begin_src sh
    $ ffmpeg .. -map '[foo]' output1.mp4 -map '[bar]' output2.mp4
  #+end_src

** Filter: geq

- Generates video from expression
- 0,0 at top left
- output values from 0-255 (?
- variables
  - N = frame, from 0
  - T = time of current frame, in seconds
  - X,Y = current sample coordinates
  - W,H = input dimensions
- functions
  - p(x,y) - lookup value at given coordinates of current plane
  - r(x,y) g(x,y) b(x,y) - "
  - alpha(x,y) - " of alpha plane
  - lum(x,y) - " of luma plane
  - cb(x,y) - " of blue-difference chroma plane
  - cr(x,y) - " of red-difference chroma plane

** Filter: avalsrc

- https://hhsprings.bitbucket.io/docs/programming/examples/ffmpeg/audio_sources/aevalsrc.html
- Generates audio from expression
- values from 0-1 (?
- Video: Making Music in Shadertoy [[https://www.youtube.com/watch?v=3mteFftC7fE][Part 1]] [[https://www.youtube.com/watch?v=CqDrw0l0tas][Part 2]] [[https://www.youtube.com/watch?v=9XeE0v5JLiQ][Part 3]]
  - Similar workflow

#+begin_src sh
  $ ffplay -t 60 -f lavfi -i <HERE>
  #  Generate silence:
  aevalsrc=0
  #  Generate a sin signal with frequency of 440 Hz, set sample rate to 8000 Hz:
  aevalsrc='sin(440*2*PI*t):s=8000'
  #  Generate a two channels signal, specify the channel layout (Front Center + Back Center) explicitly:
  aevalsrc='sin(420*2*PI*t)|cos(430*2*PI*t):c=FC|BC'
  #  Generate white noise:
  aevalsrc='-2+random(0)'
  #  Generate an amplitude modulated signal:
  aevalsrc='sin(10*2*PI*t)*sin(880*2*PI*t)'
  #  Generate 2.5 Hz binaural beats on a 360 Hz carrier:
  aevalsrc='0.1*sin(2*PI*(360-2.5/2)*t) | 0.1*sin(2*PI*(360+2.5/2)*t)'
#+end_src

* snippets

- examples https://github.com/antiboredom/infinite-video-fall-2023/blob/main/02_basics/02-ffmpeg.md
- examples https://github.com/williamgilpin/howto/blob/597f49fe02d1692c01b09e9c16af732e8c6cfe19/howto_ffmpeg.md
- art filter effect #1 https://youtu.be/nobWeGycSe8?list=PLWuCzxqIpJs_68T4ABQGNPnOYpCJ1ln13&t=1244
- dropshadow https://stackoverflow.com/questions/70368647/how-to-use-ffmpeg-to-add-a-drop-shadow
- stream to twitch https://corvid.cafe/ffstream.html
- video stabilizer https://gist.github.com/maxogden/43219d6dcb9006042849

** from frames
- ffmpeg -i test-%09d.png foo.mp4
** to frames
- ffmpeg -i input.mp4 test-%09d.png
** to frames, one per second
- ffmpeg -i input.mp4 -r 1 test-%09d.png
** slice
- cut slices, naive -copy drops frames
  ffmpeg -ss 00:02:02 \
	-to 00:02:55 \
	-i "${IN}" \
	-y \
	-async 1 feels03.mp4
** slice
- get slice of video
  ffmpeg -ss 00:01:21 -to 00:01:24
** get duration (OLD)
- get duration in seconds
  ffmpeg -i file.flv 2>&1 | grep "Duration"| cut -d ' ' -f 4 | sed s/,// | sed 's@\..*@@g' | awk '{ split($1, A, ":"); split(A[3], B, "."); print 3600*A[1] + 60*A[2] + B[1] }'
  https://superuser.com/questions/650291/how-to-get-video-duration-in-seconds
** remove audio
- Remove all audio streams / tracks https://stackoverflow.com/questions/38161697/how-to-remove-one-track-from-video-file-using-ffmpeg
  ffmpeg -i input -map 0 -map -0:a -c copy output
** concat
- concat videos https://stackoverflow.com/questions/7333232/how-to-concatenate-two-mp4-files-using-ffmpeg
  ffmpeg -i opening.mkv -i episode.mkv -i ending.mkv
  -filter_complex "[0:v] [0:a] [1:v] [1:a] [2:v] [2:a] concat=n=3:v=1:a=1 [v] [a]"
  -map "[v]" -map "[a]" output.mkv
** join video/audio
- join video with audio
  ffmpeg -i video.mp4 -i audio.mp3 -c copy output.mp4
** join video/audio, missmatched
- https://stackoverflow.com/questions/5015771/merge-video-and-audio-with-ffmpeg-loop-the-video-while-audio-is-not-over
  - join short video - long audio
    $ ffmpeg  -stream_loop -1 -i input.mp4 -i input.mp3 -shortest -map 0:v:0 -map 1:a:0 -y out.mp4
  - join long audio - short video
    $ ffmpeg  -i input.mp4 -stream_loop -1 -i input.mp3 -shortest -map 0:v:0 -map 1:a:0 -y out.mp4
** to instagram

https://www.reddit.com/r/davinciresolve/comments/1bab2yp/instagram_uploads_are_always_terrible_any_ideas/

  - example
    - Profile: High
    - 720x720 (720x960????)
    - yuv420p
    - level: 31
    - fps: 30??
  - ffmpeg
    -i "final_export.mov"
    -vf "scale=-2:1920,format=yuv420p"
    -c:v libx264
    -profile:v main
    -level:v 4.0
    -pix_fmt yuv420p
    -movflags +faststart
    -r 30Q
    -c:a aac
    -b:a 192k "instagram_optimized_export.mp4"
** bouncing text

- video without input video https://stackoverflow.com/questions/11640458/how-can-i-generate-a-video-file-directly-from-an-ffmpeg-filter-with-no-actual-in
  - ffmpeg -f lavfi -i color=color=red -t 30 red.mp4

- video text moving
  #+begin_src sh
    ffmpeg -f lavfi -i color=c=black:s=1280x720:d=10:r=30 -vf "
    drawtext=text='Bounce!'
            :fontcolor=white
            :fontsize=40
            :x='(W-tw) * abs(sin(t*2))'
            :y='(H-th) * abs(cos(t*2))'
        " -y bouncing_text.mp4
  #+end_src

* gotchas
- of filters
  - missing '' for arguments
  - manual identation almost obligatory
  - keeping track of the differences between
    - :
    - ,
    - ;
* articles

- 23 [[https://www.canva.dev/blog/engineering/a-journey-through-colour-space-with-ffmpeg/][A journey through color space with FFmpeg]]
- 23 [[https://xeiaso.net/blog/video-compression/][Video Compression for Mere Mortals]]
- 23 https://dev.to/video/exploring-video-generators-in-ffmpeg-4ehc
- 22 [[https://img.ly/blog/ultimate-guide-to-ffmpeg/][FFmpeg - The Ultimate Guide]]
- 22 https://drewdevault.com/2022/10/12/In-praise-of-ffmpeg.html
- 22 [[https://blog.gdeltproject.org/experiments-with-ffmpeg-scene-detection-to-explore-the-parallel-universe-of-russian-state-television-channel-russia1/][Experiments With FFMPEG & Scene Detection To Explore The Parallel Universe Of Russian State Television Channel RUSSIA1]]
- 21 https://tratt.net/laurie/blog/2021/automatic_video_editing.html
- 20 [[https://blog.gdeltproject.org/using-ffmpegs-scene-detection-to-generate-a-visual-shot-summary-of-television-news/][Using FFMPEG's Scene Detection To Generate A Visual Shot Summary Of Television News]]
  - fixed output size, filled by black
  - Examples
    #+begin_src sh
      -vf 'select=gt(scene,0.4),scale=160:-1,tile=6x80'                       -frames:v 1 -qscale:v 3 out.jpg
      -f lavfi -i 'movie=bar.mp4,scdet=s=1:t=14' -vf 'scale=160:-1,tile=6x85' -frames:v 1 -qscale:v 3 scprev.jpg
    #+end_src
- 20 [[https://www.hellocatfood.com/motion-interpolation-for-glitch-aesthetics-using-ffmpeg-part-0/][Motion Interpolation for Glitch Aesthetics using FFmpeg part 0]]
- 20 [[https://gariany.com/2020/08/ffmpeg-a-step-by-step-guide-to-creating-a-retro-video-filter/][FFmpeg: A Step-by-Step Guide to Creating a Retro Video Filter]]
- 19 [[https://www.glitch.cool/meii/intro-to-ffmpeg-audio-to-video-filters][Intro to ffmpeg: audio-to-video filters]]
- 15 [[https://blog.pkh.me/p/21-high-quality-gif-with-ffmpeg.html][High quality GIF with FFmpeg]]

** filters

- https://trac.ffmpeg.org/wiki/FancyFilteringExamples
- 23 [[https://igor.technology/interesting-things-you-can-do-with-ffmpeg/][Interesting things you can do with FFmpeg]]
- 17 https://nico-lab.net/testsrc_with_ffmpeg/

* videos

- PhreakNIC20: FFmpeg I didn't know it could do that! - poiupoiu https://www.youtube.com/watch?v=Dl2kUskbIo4
- FFMPEG Advanced Techniques
  - goes over many effects https://www.youtube.com/watch?v=M58rc7cxl_s
  - Filtergraphs & Timeline https://www.youtube.com/watch?v=hElDsyuAQDA

** Course: Video Art with FFMPEG

https://www.youtube.com/playlist?list=PLWuCzxqIpJs_68T4ABQGNPnOYpCJ1ln13

*** 1) FFMPEG Basics
*** 2) Video Filters, Complex Filter

- https://www.youtube.com/watch?v=imvrFhpk-d4
- Artists
  - Martin Arnold
  - Gregg Biermann
  - Holly Fisher
  - Noemi Schipfer
- No built-in support in the filter variales to tell how long the video is.
- Timeline supported filters may have an =enable= option
  - to control when enable it
  - use it with the *between()* operator
- Filter: =rotate=
  - can be controlled by T
  - hypot(iw,ih)+1 to not crop on rotation
- Filter: =hue= an hsv filter
  - hue=h=180
  - hue=H=PI
  - saturation: default 1, from -10 to 10, 0 grayscale
    - hue=s=0
  - brightness: default 0, from -10 to 10
    - hue=b=
- Filter: =setpts=
  - setpts=0.5*PTS - twice speed
- Filter: =overlay=
  - arguments in stacking order: bottom first
- Filter: =split=
  - creates N copies of the given input video
  - with no arguments makes an extra copy of the video
- Filter: =vflip=, =hflip=
- Filter: =rgbashift=
  - does not take T as input
  - can be workaround with "python" templating
  - example
    #+begin_src python
      import math
      f = ""
      v1 = 8
      fps = 30
      for i in range(v1*fps):
          amt  = math.ceil(mat.cos((i/fps)*(math.pi/2))*75)
          amt2 = math.ceil(mat.sin((i/fps)*(math.pi/2))*75)
          if i == 0:
              f+=f"rgbashift=enable='eq(n,{str(i)}):bv='{str(amt)}':gb='{amt2}'"
          else:
              f+=f"rgbashift=enable='eq(n,{str(i)}):bv='{str(amt)}'"
       print(f)
    #+end_src

*** 3) Blend, Mask, and Time Transformations

https://www.youtube.com/watch?v=niGYQAHVfqs

- Prework:
  - filters: lagfun, bilateral, hue, overlay
  - in ffmpeg looping is hard, you can't say take the beginning and the end
    ffmpeg works only on forward pass, reads until it ends

- Use =-shortest= when you have +1 video input
- Filter: =ovelay= to apply a mask
  - Masks are images or videos
  - Masks are meant to be mostly imported, not generated
- Filter: =blend= 2 video frames into each other
  - all_mode
- Filter: =lumakey=
- Filter: =colorhold= it removes everything else BUT that color, replacing it with neutral gray
- Filter: =colorkey= replaces RGB color for transparency
- Filter: =chromakey= mask to replace given to color to transparency
  - chromakey=0x00FF00:0.25:0.08
    chromakey=<COLOR_>:<similarity>:<blend>
- Filter: =setpts= set presentation timestamp
  - relative to *start time*
  - setpts=0.5*PTS faster
  - setpts=2*PTS slower
- Filter: =minterpolate= to interpolate frames, useful with setpts
  - https://www.hellocatfood.com/motion-interpolation-for-glitch-aesthetics-using-ffmpeg-part-0/
- Filter: =concat=
  - [0][1][2]concat=n=3
- Filter: =tpad= time padding
  - Example: add 1 second of black at the beginning of the video
    - tpad=start_mode=add:start_duration=1:color=0x000000
- Filter: =trim= cuts a video by a start and end position
  - trim=0:1.0
  - add *setpts=PTS-STARTPTS* to preserve the start time

- There are times where the *start time* position might not be 0.00
  - if you trimmed a video

**** Example: Slitscan effect

- strips of video with increasing start delay

#+begin_src python
  width = 1920
  height = 1080
  strip = 20
  fps = 23.98
  offset = 3/fps

  s = f"[0:v]split={int(heigh/strip)}"
  for i in range(int(height/strip)):
      s += f"[v{i}]"
  s += ';'
  print(s)

  t = ''
  for i in range(int(height/strip)):
      t += f"tpad=start_mode=add:start_duration={offset*i}:color=0x000000,crop={width}:{strip}:0:{i*strip}[v{i}]"
  print(t)

  stack = ''
  for i in range(int(height/strip)):
      stack += f"[v{i}]"
  stack += f"vstack=inputs={int(height/strip)}"
  print(stack)
#+end_src

*** 4) Python Scripts, Gifs, Scene Detection
